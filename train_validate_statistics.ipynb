{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee2fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone 'https://github.com/Ulyssesllc/PointWSSIS.git'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ad5d8a",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6110d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "# Set workspace root\n",
    "WORKSPACE_ROOT = Path(os.getcwd())\n",
    "ADELAIDET_ROOT = WORKSPACE_ROOT / \"AdelaiDet\"\n",
    "MASKREFINE_ROOT = WORKSPACE_ROOT / \"MaskRefineNet\"\n",
    "DETECTRON2_ROOT = WORKSPACE_ROOT / \"detectron2\"\n",
    "\n",
    "print(f\"Workspace Root: {WORKSPACE_ROOT}\")\n",
    "print(f\"AdelaiDet Root: {ADELAIDET_ROOT}\")\n",
    "print(f\"MaskRefineNet Root: {MASKREFINE_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e0c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "class Config:\n",
    "    # Dataset configuration\n",
    "    DATA_ROOT = \"YOUR_DATA_ROOT\"  # <-- Update this to your data root\n",
    "    DATASET = \"coco\"  # or \"BDD100K\"\n",
    "    SUBSET = \"5p\"  # Options: 1p, 2p, 5p, 10p, 20p, 30p, 50p\n",
    "    \n",
    "    # Training configuration\n",
    "    NUM_GPUS = 1  # Will be auto-detected if not specified\n",
    "    SEED = 1\n",
    "    \n",
    "    # Paths (auto-generated based on subset)\n",
    "    @property\n",
    "    def annotations_dir(self):\n",
    "        return Path(self.DATA_ROOT) / \"coco\" / \"annotations\"\n",
    "    \n",
    "    @property\n",
    "    def strong_json(self):\n",
    "        return f\"instances_train2017_{self.SUBSET}_s.json\"\n",
    "    \n",
    "    @property\n",
    "    def weak_json(self):\n",
    "        return f\"instances_train2017_{self.SUBSET}_w.json\"\n",
    "    \n",
    "    @property\n",
    "    def sw_refined_json(self):\n",
    "        return f\"instances_train2017_{self.SUBSET}_sw_refined.json\"\n",
    "\n",
    "config = Config()\n",
    "print(f\"Dataset: {config.DATASET}\")\n",
    "print(f\"Subset: {config.SUBSET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25fadf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect number of GPUs\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        config.NUM_GPUS = torch.cuda.device_count()\n",
    "        print(f\"Detected {config.NUM_GPUS} GPU(s)\")\n",
    "        for i in range(config.NUM_GPUS):\n",
    "            print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    else:\n",
    "        print(\"No GPU detected, using CPU (not recommended for training)\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c04c3bb",
   "metadata": {},
   "source": [
    "## 2. Dataset Statistics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9327a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coco_annotations(json_path):\n",
    "    \"\"\"Load COCO format annotations\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def analyze_annotations(data, name=\"Dataset\"):\n",
    "    \"\"\"Analyze annotation statistics\"\"\"\n",
    "    stats = {\n",
    "        'name': name,\n",
    "        'num_images': len(data.get('images', [])),\n",
    "        'num_annotations': len(data.get('annotations', [])),\n",
    "        'num_categories': len(data.get('categories', [])),\n",
    "    }\n",
    "    \n",
    "    # Category distribution\n",
    "    category_counts = defaultdict(int)\n",
    "    category_names = {cat['id']: cat['name'] for cat in data.get('categories', [])}\n",
    "    \n",
    "    for ann in data.get('annotations', []):\n",
    "        cat_id = ann['category_id']\n",
    "        category_counts[category_names.get(cat_id, f'cat_{cat_id}')] += 1\n",
    "    \n",
    "    stats['category_distribution'] = dict(category_counts)\n",
    "    \n",
    "    # Annotations per image\n",
    "    image_ann_counts = defaultdict(int)\n",
    "    for ann in data.get('annotations', []):\n",
    "        image_ann_counts[ann['image_id']] += 1\n",
    "    \n",
    "    ann_counts = list(image_ann_counts.values())\n",
    "    if ann_counts:\n",
    "        stats['avg_annotations_per_image'] = np.mean(ann_counts)\n",
    "        stats['max_annotations_per_image'] = max(ann_counts)\n",
    "        stats['min_annotations_per_image'] = min(ann_counts)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def print_stats(stats):\n",
    "    \"\"\"Print dataset statistics\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Dataset: {stats['name']}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"  Images: {stats['num_images']:,}\")\n",
    "    print(f\"  Annotations: {stats['num_annotations']:,}\")\n",
    "    print(f\"  Categories: {stats['num_categories']}\")\n",
    "    if 'avg_annotations_per_image' in stats:\n",
    "        print(f\"  Avg annotations/image: {stats['avg_annotations_per_image']:.2f}\")\n",
    "        print(f\"  Max annotations/image: {stats['max_annotations_per_image']}\")\n",
    "        print(f\"  Min annotations/image: {stats['min_annotations_per_image']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2851a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze available annotation files\n",
    "def analyze_all_subsets(annotations_dir):\n",
    "    \"\"\"Analyze all available annotation subsets\"\"\"\n",
    "    subsets = ['1p', '2p', '5p', '10p', '20p', '30p', '50p']\n",
    "    all_stats = []\n",
    "    \n",
    "    annotations_path = Path(annotations_dir)\n",
    "    \n",
    "    if not annotations_path.exists():\n",
    "        print(f\"Annotations directory not found: {annotations_path}\")\n",
    "        print(\"Please update config.DATA_ROOT to point to your data directory\")\n",
    "        return all_stats\n",
    "    \n",
    "    for subset in subsets:\n",
    "        strong_file = annotations_path / f\"instances_train2017_{subset}_s.json\"\n",
    "        weak_file = annotations_path / f\"instances_train2017_{subset}_w.json\"\n",
    "        \n",
    "        if strong_file.exists():\n",
    "            data = load_coco_annotations(strong_file)\n",
    "            stats = analyze_annotations(data, f\"{subset} Strong\")\n",
    "            all_stats.append(stats)\n",
    "            print_stats(stats)\n",
    "        \n",
    "        if weak_file.exists():\n",
    "            data = load_coco_annotations(weak_file)\n",
    "            stats = analyze_annotations(data, f\"{subset} Weak\")\n",
    "            all_stats.append(stats)\n",
    "            print_stats(stats)\n",
    "    \n",
    "    return all_stats\n",
    "\n",
    "# Run analysis\n",
    "all_stats = analyze_all_subsets(config.annotations_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e844f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category_distribution(stats_list, top_n=20):\n",
    "    \"\"\"Plot category distribution for multiple datasets\"\"\"\n",
    "    if not stats_list:\n",
    "        print(\"No statistics available to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(len(stats_list), 1, figsize=(14, 4*len(stats_list)))\n",
    "    if len(stats_list) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, stats in zip(axes, stats_list):\n",
    "        cat_dist = stats.get('category_distribution', {})\n",
    "        if not cat_dist:\n",
    "            continue\n",
    "            \n",
    "        # Sort by count and take top N\n",
    "        sorted_cats = sorted(cat_dist.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        categories, counts = zip(*sorted_cats)\n",
    "        \n",
    "        ax.bar(range(len(categories)), counts, color='steelblue')\n",
    "        ax.set_xticks(range(len(categories)))\n",
    "        ax.set_xticklabels(categories, rotation=45, ha='right')\n",
    "        ax.set_title(f\"{stats['name']} - Top {top_n} Categories\")\n",
    "        ax.set_ylabel('Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot distributions\n",
    "if all_stats:\n",
    "    plot_category_distribution(all_stats[:2])  # Plot first 2 subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f76516",
   "metadata": {},
   "source": [
    "## 3. Training Pipeline Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66961f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters for different subsets\n",
    "TRAINING_CONFIGS = {\n",
    "    '1p': {\n",
    "        'learning_rate': 0.05,\n",
    "        'decay_steps': (5000, 8000),\n",
    "        'train_iter': 10001,\n",
    "        'mrn_train_iters': 200000,\n",
    "        'mrn_warm_iters': 2000,\n",
    "    },\n",
    "    '2p': {\n",
    "        'learning_rate': 0.05,\n",
    "        'decay_steps': (15000, 20000),\n",
    "        'train_iter': 25001,\n",
    "        'mrn_train_iters': 200000,\n",
    "        'mrn_warm_iters': 2000,\n",
    "    },\n",
    "    '5p': {\n",
    "        'learning_rate': 0.05,\n",
    "        'decay_steps': (20000, 25000),\n",
    "        'train_iter': 30001,\n",
    "        'mrn_train_iters': 200000,\n",
    "        'mrn_warm_iters': 2000,\n",
    "    },\n",
    "    '10p': {\n",
    "        'learning_rate': 0.05,\n",
    "        'decay_steps': (35000, 40000),\n",
    "        'train_iter': 45001,\n",
    "        'mrn_train_iters': 200000,\n",
    "        'mrn_warm_iters': 2000,\n",
    "    },\n",
    "    '20p': {\n",
    "        'learning_rate': 0.05,\n",
    "        'decay_steps': (90000, 110000),\n",
    "        'train_iter': 120001,\n",
    "        'mrn_train_iters': 200000,\n",
    "        'mrn_warm_iters': 2000,\n",
    "    },\n",
    "    '30p': {\n",
    "        'learning_rate': 0.05,\n",
    "        'decay_steps': (120000, 150000),\n",
    "        'train_iter': 160001,\n",
    "        'mrn_train_iters': 200000,\n",
    "        'mrn_warm_iters': 2000,\n",
    "    },\n",
    "    '50p': {\n",
    "        'learning_rate': 0.05,\n",
    "        'decay_steps': (210000, 250000),\n",
    "        'train_iter': 270001,\n",
    "        'mrn_train_iters': 200000,\n",
    "        'mrn_warm_iters': 2000,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Get config for current subset\n",
    "train_config = TRAINING_CONFIGS.get(config.SUBSET, TRAINING_CONFIGS['5p'])\n",
    "print(f\"Training Configuration for {config.SUBSET}:\")\n",
    "for key, value in train_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9318bd22",
   "metadata": {},
   "source": [
    "## 4. Step 1: Train Teacher Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c880f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_teacher_training_command(config, train_config):\n",
    "    \"\"\"Generate command for training teacher network\"\"\"\n",
    "    exp_name = f\"SOLOv2_R101_coco{config.SUBSET}_teacher\"\n",
    "    trainsets = f\"('coco_2017_train_{config.SUBSET}_s',)\"\n",
    "    testsets = \"('coco_2017_val',)\"\n",
    "    \n",
    "    cmd = f\"\"\"\n",
    "cd {ADELAIDET_ROOT}\n",
    "\n",
    "export DETECTRON2_DATASETS={config.DATA_ROOT}\n",
    "\n",
    "OMP_NUM_THREADS=1 python -W ignore tools/train_net.py \\\\\n",
    "    --config-file configs/PointWSSIS/R101_teacher.yaml \\\\\n",
    "    --num-gpus {config.NUM_GPUS} \\\\\n",
    "    SEED {config.SEED} \\\\\n",
    "    OUTPUT_DIR training_dir/{exp_name} \\\\\n",
    "    DATASETS.TRAIN {trainsets} \\\\\n",
    "    DATASETS.TEST {testsets} \\\\\n",
    "    SOLVER.STEPS {train_config['decay_steps']} \\\\\n",
    "    SOLVER.MAX_ITER {train_config['train_iter']} \\\\\n",
    "    SOLVER.BASE_LR {train_config['learning_rate']} \\\\\n",
    "    MODEL.SOLOV2.PROMPT point \\\\\n",
    "    MODEL.SOLOV2.EVAL_PSEUDO_LABEL True \\\\\n",
    "    TEST.EVAL_PERIOD 5000\n",
    "\"\"\"\n",
    "    return cmd, exp_name\n",
    "\n",
    "teacher_cmd, teacher_exp_name = generate_teacher_training_command(config, train_config)\n",
    "print(\"Teacher Network Training Command:\")\n",
    "print(teacher_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b33c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run teacher training (uncomment to execute)\n",
    "# Note: This will take a significant amount of time depending on your hardware\n",
    "\n",
    "RUN_TRAINING = False  # Set to True to run training\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    os.chdir(ADELAIDET_ROOT)\n",
    "    os.environ['DETECTRON2_DATASETS'] = config.DATA_ROOT\n",
    "    \n",
    "    # Run the training command\n",
    "    result = subprocess.run(\n",
    "        teacher_cmd.split('\\n')[-2].strip().replace('\\\\\\n', '').split(),\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    print(result.stdout)\n",
    "    if result.stderr:\n",
    "        print(\"Errors:\", result.stderr)\n",
    "else:\n",
    "    print(\"Training is disabled. Set RUN_TRAINING = True to execute.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f81ee35",
   "metadata": {},
   "source": [
    "## 5. Step 2: Generate Pseudo Labels (Inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61959484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inference_command(config, train_config, teacher_exp_name):\n",
    "    \"\"\"Generate command for generating pseudo labels\"\"\"\n",
    "    testsets = f\"('coco_2017_train_{config.SUBSET}_w',)\"\n",
    "    \n",
    "    cmd = f\"\"\"\n",
    "cd {ADELAIDET_ROOT}\n",
    "\n",
    "export DETECTRON2_DATASETS={config.DATA_ROOT}\n",
    "\n",
    "OMP_NUM_THREADS=1 python -W ignore tools/train_net.py \\\\\n",
    "    --config-file configs/PointWSSIS/R101_teacher.yaml \\\\\n",
    "    --num-gpus {config.NUM_GPUS} \\\\\n",
    "    --eval-only \\\\\n",
    "    MODEL.WEIGHTS training_dir/{teacher_exp_name}/model_final.pth \\\\\n",
    "    OUTPUT_DIR inference_dir/{teacher_exp_name} \\\\\n",
    "    MODEL.SOLOV2.FPN_SCALE_RANGES \"((1,100000),(1,100000),(1,100000),(1,100000),(1,100000))\" \\\\\n",
    "    MODEL.SOLOV2.NMS_TYPE mask \\\\\n",
    "    MODEL.SOLOV2.PROMPT point \\\\\n",
    "    DATASETS.TEST {testsets}\n",
    "\"\"\"\n",
    "    return cmd\n",
    "\n",
    "inference_cmd = generate_inference_command(config, train_config, teacher_exp_name)\n",
    "print(\"Pseudo Label Generation Command:\")\n",
    "print(inference_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16150602",
   "metadata": {},
   "source": [
    "## 6. Step 3: Train MaskRefineNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e5078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mrn_training_command(config, train_config, teacher_exp_name):\n",
    "    \"\"\"Generate command for training MaskRefineNet\"\"\"\n",
    "    mrn_exp_name = f\"MRN_{config.SUBSET}\"\n",
    "    \n",
    "    cmd = f\"\"\"\n",
    "cd {MASKREFINE_ROOT}\n",
    "\n",
    "torchrun --standalone --nnodes=1 --nproc_per_node={config.NUM_GPUS} main.py \\\\\n",
    "    --data_root {config.DATA_ROOT} \\\\\n",
    "    --workspace results \\\\\n",
    "    --exp_name {mrn_exp_name} \\\\\n",
    "    --train_iters {train_config['mrn_train_iters']} \\\\\n",
    "    --warm_iters {train_config['mrn_warm_iters']} \\\\\n",
    "    --val_interval 5000 \\\\\n",
    "    --weak_pth ../AdelaiDet/inference_dir/{teacher_exp_name}_strong_1/inference/instances_predictions.pth \\\\\n",
    "               ../AdelaiDet/inference_dir/{teacher_exp_name}_strong_2/inference/instances_predictions.pth \\\\\n",
    "    --gt_json {config.strong_json} \\\\\n",
    "    --eval_pth ../AdelaiDet/inference_dir/{teacher_exp_name}/inference/instances_predictions.pth \\\\\n",
    "    --amp\n",
    "\"\"\"\n",
    "    return cmd, mrn_exp_name\n",
    "\n",
    "mrn_cmd, mrn_exp_name = generate_mrn_training_command(config, train_config, teacher_exp_name)\n",
    "print(\"MaskRefineNet Training Command:\")\n",
    "print(mrn_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f803b8ad",
   "metadata": {},
   "source": [
    "## 7. Step 4: Merge Refined Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d482bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_merge_command(config, teacher_exp_name, mrn_exp_name):\n",
    "    \"\"\"Generate command for merging strong and refined weak labels\"\"\"\n",
    "    \n",
    "    cmd = f\"\"\"\n",
    "cd {MASKREFINE_ROOT}\n",
    "\n",
    "torchrun --standalone --nnodes=1 --nproc_per_node={config.NUM_GPUS} merge_strong_and_refined_weak_labels.py \\\\\n",
    "    --data_root {config.DATA_ROOT} \\\\\n",
    "    --ckpt results/{mrn_exp_name}/ckpt/best_AP.pt \\\\\n",
    "    --dataset coco \\\\\n",
    "    --size 256 \\\\\n",
    "    --weak_pth ../AdelaiDet/inference_dir/{teacher_exp_name}/inference/instances_predictions.pth \\\\\n",
    "    --weak_json {config.DATA_ROOT}/coco/annotations/instances_train2017_{config.SUBSET}_w.json \\\\\n",
    "    --strong_json {config.DATA_ROOT}/coco/annotations/instances_train2017_{config.SUBSET}_s.json \\\\\n",
    "    --save_path {config.DATA_ROOT}/coco/annotations/instances_train2017_{config.SUBSET}_sw_refined.json\n",
    "\"\"\"\n",
    "    return cmd\n",
    "\n",
    "merge_cmd = generate_merge_command(config, teacher_exp_name, mrn_exp_name)\n",
    "print(\"Label Merging Command:\")\n",
    "print(merge_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb94867",
   "metadata": {},
   "source": [
    "## 8. Step 5: Train Student Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb678fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_student_training_command(config):\n",
    "    \"\"\"Generate command for training student network\"\"\"\n",
    "    exp_name = f\"SOLOv2_R101_coco{config.SUBSET}_sw_refined\"\n",
    "    trainsets = f\"('coco_2017_train_{config.SUBSET}_sw_refined',)\"\n",
    "    testsets = \"('coco_2017_val',)\"\n",
    "    \n",
    "    cmd = f\"\"\"\n",
    "cd {ADELAIDET_ROOT}\n",
    "\n",
    "export DETECTRON2_DATASETS={config.DATA_ROOT}\n",
    "\n",
    "OMP_NUM_THREADS=1 python -W ignore tools/train_net.py \\\\\n",
    "    --config-file configs/SOLOv2/R101_3x.yaml \\\\\n",
    "    --num-gpus {config.NUM_GPUS} \\\\\n",
    "    SEED {config.SEED} \\\\\n",
    "    OUTPUT_DIR training_dir/{exp_name} \\\\\n",
    "    DATASETS.TRAIN {trainsets} \\\\\n",
    "    DATASETS.TEST {testsets} \\\\\n",
    "    TEST.EVAL_PERIOD 5000\n",
    "\"\"\"\n",
    "    return cmd, exp_name\n",
    "\n",
    "student_cmd, student_exp_name = generate_student_training_command(config)\n",
    "print(\"Student Network Training Command:\")\n",
    "print(student_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04223f34",
   "metadata": {},
   "source": [
    "## 9. Evaluation & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6cd8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_evaluation_command(config, exp_name, model_path):\n",
    "    \"\"\"Generate command for model evaluation\"\"\"\n",
    "    testsets = \"('coco_2017_val',)\"\n",
    "    \n",
    "    cmd = f\"\"\"\n",
    "cd {ADELAIDET_ROOT}\n",
    "\n",
    "export DETECTRON2_DATASETS={config.DATA_ROOT}\n",
    "\n",
    "OMP_NUM_THREADS=1 python -W ignore tools/train_net.py \\\\\n",
    "    --config-file configs/SOLOv2/R101_3x.yaml \\\\\n",
    "    --num-gpus {config.NUM_GPUS} \\\\\n",
    "    --eval-only \\\\\n",
    "    MODEL.WEIGHTS {model_path} \\\\\n",
    "    OUTPUT_DIR evaluation_dir/{exp_name} \\\\\n",
    "    DATASETS.TEST {testsets}\n",
    "\"\"\"\n",
    "    return cmd\n",
    "\n",
    "# Evaluation command for the student network\n",
    "student_model_path = f\"training_dir/{student_exp_name}/model_final.pth\"\n",
    "eval_cmd = generate_evaluation_command(config, student_exp_name, student_model_path)\n",
    "print(\"Evaluation Command:\")\n",
    "print(eval_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6119c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected results comparison\n",
    "EXPECTED_RESULTS = {\n",
    "    '1p': 24.0,\n",
    "    '2p': 25.3,\n",
    "    '5p': 33.7,\n",
    "    '10p': 35.8,\n",
    "    '20p': 37.1,\n",
    "    '30p': 38.0,\n",
    "    '50p': 38.8,\n",
    "}\n",
    "\n",
    "def plot_expected_results():\n",
    "    \"\"\"Plot expected results from the paper\"\"\"\n",
    "    subsets = list(EXPECTED_RESULTS.keys())\n",
    "    mAPs = list(EXPECTED_RESULTS.values())\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(subsets, mAPs, color='steelblue', edgecolor='black')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, mAP in zip(bars, mAPs):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                 f'{mAP}%', ha='center', va='bottom', fontsize=11)\n",
    "    \n",
    "    plt.xlabel('Subset (% of fully labeled data)', fontsize=12)\n",
    "    plt.ylabel('COCO test-dev mAP (%)', fontsize=12)\n",
    "    plt.title('PointWSSIS Expected Results (from Paper)', fontsize=14)\n",
    "    plt.ylim(0, 45)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_expected_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe212f88",
   "metadata": {},
   "source": [
    "## 9.1 Verify Claimed Results with Pre-trained Checkpoints\n",
    "\n",
    "The authors provide pre-trained checkpoints for all subsets. We can download and evaluate them to verify the claimed mAP scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc02c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-trained checkpoint URLs from the official repo\n",
    "PRETRAINED_CHECKPOINTS = {\n",
    "    '1p': {\n",
    "        'teacher': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_1p_teacher.pth',\n",
    "        'mrn': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_1p_MRN.pt',\n",
    "        'student': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_1p_student.pth',\n",
    "        'expected_mAP': 24.0,\n",
    "    },\n",
    "    '2p': {\n",
    "        'teacher': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_2p_teacher.pth',\n",
    "        'mrn': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_2p_MRN.pt',\n",
    "        'student': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_2p_student.pth',\n",
    "        'expected_mAP': 25.3,\n",
    "    },\n",
    "    '5p': {\n",
    "        'teacher': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_5p_teacher.pth',\n",
    "        'mrn': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_5p_MRN.pt',\n",
    "        'student': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_5p_student.pth',\n",
    "        'expected_mAP': 33.7,\n",
    "    },\n",
    "    '10p': {\n",
    "        'teacher': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_10p_teacher.pth',\n",
    "        'mrn': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_10p_MRN.pt',\n",
    "        'student': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_10p_student.pth',\n",
    "        'expected_mAP': 35.8,\n",
    "    },\n",
    "    '20p': {\n",
    "        'teacher': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_20p_teacher.pth',\n",
    "        'mrn': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_20p_MRN.pt',\n",
    "        'student': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_20p_student.pth',\n",
    "        'expected_mAP': 37.1,\n",
    "    },\n",
    "    '30p': {\n",
    "        'teacher': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_30p_teacher.pth',\n",
    "        'mrn': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_30p_MRN.pt',\n",
    "        'student': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_30p_student.pth',\n",
    "        'expected_mAP': 38.0,\n",
    "    },\n",
    "    '50p': {\n",
    "        'teacher': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_50p_teacher.pth',\n",
    "        'mrn': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_50p_MRN.pt',\n",
    "        'student': 'https://github.com/clovaai/PointWSSIS/releases/download/ckpt/coco_50p_student.pth',\n",
    "        'expected_mAP': 38.8,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"Available pre-trained checkpoints:\")\n",
    "for subset, ckpts in PRETRAINED_CHECKPOINTS.items():\n",
    "    print(f\"  {subset}: Expected mAP = {ckpts['expected_mAP']}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b744d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "\n",
    "def download_checkpoint(url, save_dir, filename=None):\n",
    "    \"\"\"Download a checkpoint file\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    if filename is None:\n",
    "        filename = url.split('/')[-1]\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    \n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"  ✓ Already exists: {save_path}\")\n",
    "        return save_path\n",
    "    \n",
    "    print(f\"  Downloading: {filename}...\")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, save_path)\n",
    "        print(f\"  ✓ Saved to: {save_path}\")\n",
    "        return save_path\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Failed to download: {e}\")\n",
    "        return None\n",
    "\n",
    "def download_checkpoints_for_subset(subset, ckpt_dir=\"pretrained_checkpoints\"):\n",
    "    \"\"\"Download all checkpoints for a specific subset\"\"\"\n",
    "    if subset not in PRETRAINED_CHECKPOINTS:\n",
    "        print(f\"Unknown subset: {subset}\")\n",
    "        return None\n",
    "    \n",
    "    ckpts = PRETRAINED_CHECKPOINTS[subset]\n",
    "    subset_dir = os.path.join(ckpt_dir, subset)\n",
    "    \n",
    "    print(f\"\\nDownloading checkpoints for {subset} subset:\")\n",
    "    paths = {}\n",
    "    for model_type in ['teacher', 'mrn', 'student']:\n",
    "        url = ckpts[model_type]\n",
    "        path = download_checkpoint(url, subset_dir)\n",
    "        paths[model_type] = path\n",
    "    \n",
    "    return paths\n",
    "\n",
    "# Download checkpoints for the configured subset\n",
    "# Uncomment the line below to download\n",
    "# downloaded_paths = download_checkpoints_for_subset(config.SUBSET)\n",
    "\n",
    "print(f\"\\nTo download checkpoints for {config.SUBSET} subset, uncomment and run:\")\n",
    "print(f\"  downloaded_paths = download_checkpoints_for_subset('{config.SUBSET}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa6acf9",
   "metadata": {},
   "source": [
    "### Run Evaluation to Verify Claimed Results\n",
    "\n",
    "After downloading checkpoints, run evaluation on COCO val2017 to verify the claimed mAP scores.\n",
    "\n",
    "**Note:** The paper reports results on COCO **test-dev**, but we can use **val2017** for verification (results will be slightly different but should be close)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a65dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_verification_command(subset, model_type='student', ckpt_dir=\"pretrained_checkpoints\"):\n",
    "    \"\"\"Generate command to evaluate a pre-trained checkpoint\"\"\"\n",
    "    \n",
    "    ckpts = PRETRAINED_CHECKPOINTS.get(subset, {})\n",
    "    expected_mAP = ckpts.get('expected_mAP', 'N/A')\n",
    "    \n",
    "    if model_type == 'student':\n",
    "        ckpt_path = f\"{ckpt_dir}/{subset}/coco_{subset}_student.pth\"\n",
    "        config_file = \"configs/SOLOv2/R101_3x.yaml\"\n",
    "    else:  # teacher\n",
    "        ckpt_path = f\"{ckpt_dir}/{subset}/coco_{subset}_teacher.pth\"\n",
    "        config_file = \"configs/PointWSSIS/R101_teacher.yaml\"\n",
    "    \n",
    "    cmd = f\"\"\"\n",
    "# Evaluate {model_type} model for {subset} subset\n",
    "# Expected mAP (test-dev): {expected_mAP}%\n",
    "\n",
    "cd {ADELAIDET_ROOT}\n",
    "\n",
    "export DETECTRON2_DATASETS={config.DATA_ROOT}\n",
    "\n",
    "OMP_NUM_THREADS=1 python -W ignore tools/train_net.py \\\\\n",
    "    --config-file {config_file} \\\\\n",
    "    --num-gpus {config.NUM_GPUS} \\\\\n",
    "    --eval-only \\\\\n",
    "    MODEL.WEIGHTS {ckpt_path} \\\\\n",
    "    OUTPUT_DIR evaluation_results/{subset}_{model_type} \\\\\n",
    "    DATASETS.TEST \"('coco_2017_val',)\"\n",
    "\"\"\"\n",
    "    return cmd\n",
    "\n",
    "# Generate verification commands for the current subset\n",
    "print(\"=\"*70)\n",
    "print(f\"VERIFICATION COMMANDS FOR {config.SUBSET} SUBSET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n--- Student Model (Final Results) ---\")\n",
    "print(generate_verification_command(config.SUBSET, 'student'))\n",
    "\n",
    "print(\"\\n--- Teacher Model ---\")\n",
    "print(generate_verification_command(config.SUBSET, 'teacher'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64acb8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_verification(subset, model_type='student', ckpt_dir=\"pretrained_checkpoints\"):\n",
    "    \"\"\"\n",
    "    Run evaluation and parse results to verify claimed mAP.\n",
    "    Returns the actual mAP from evaluation.\n",
    "    \"\"\"\n",
    "    import subprocess\n",
    "    import re\n",
    "    \n",
    "    ckpts = PRETRAINED_CHECKPOINTS.get(subset, {})\n",
    "    expected_mAP = ckpts.get('expected_mAP', 0)\n",
    "    \n",
    "    if model_type == 'student':\n",
    "        ckpt_path = os.path.join(WORKSPACE_ROOT, ckpt_dir, subset, f\"coco_{subset}_student.pth\")\n",
    "        config_file = \"configs/SOLOv2/R101_3x.yaml\"\n",
    "    else:\n",
    "        ckpt_path = os.path.join(WORKSPACE_ROOT, ckpt_dir, subset, f\"coco_{subset}_teacher.pth\")\n",
    "        config_file = \"configs/PointWSSIS/R101_teacher.yaml\"\n",
    "    \n",
    "    if not os.path.exists(ckpt_path):\n",
    "        print(f\"✗ Checkpoint not found: {ckpt_path}\")\n",
    "        print(f\"  Please download first using: download_checkpoints_for_subset('{subset}')\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Running evaluation for {subset} {model_type}...\")\n",
    "    print(f\"  Checkpoint: {ckpt_path}\")\n",
    "    print(f\"  Expected mAP (test-dev): {expected_mAP}%\")\n",
    "    \n",
    "    # Build the command\n",
    "    cmd = [\n",
    "        \"python\", \"-W\", \"ignore\", \"tools/train_net.py\",\n",
    "        \"--config-file\", config_file,\n",
    "        \"--num-gpus\", str(config.NUM_GPUS),\n",
    "        \"--eval-only\",\n",
    "        \"MODEL.WEIGHTS\", ckpt_path,\n",
    "        \"OUTPUT_DIR\", f\"evaluation_results/{subset}_{model_type}\",\n",
    "        \"DATASETS.TEST\", \"('coco_2017_val',)\"\n",
    "    ]\n",
    "    \n",
    "    # Set environment and run\n",
    "    env = os.environ.copy()\n",
    "    env['DETECTRON2_DATASETS'] = config.DATA_ROOT\n",
    "    env['OMP_NUM_THREADS'] = '1'\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            cmd,\n",
    "            cwd=str(ADELAIDET_ROOT),\n",
    "            env=env,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=3600  # 1 hour timeout\n",
    "        )\n",
    "        \n",
    "        # Parse output for mAP\n",
    "        output = result.stdout + result.stderr\n",
    "        \n",
    "        # Look for segm AP in output\n",
    "        ap_match = re.search(r'segm.*?AP[:\\s]+(\\d+\\.?\\d*)', output)\n",
    "        if ap_match:\n",
    "            actual_mAP = float(ap_match.group(1))\n",
    "            return actual_mAP\n",
    "        \n",
    "        # Alternative pattern\n",
    "        ap_match = re.search(r'\\|.*?AP.*?\\|.*?(\\d+\\.?\\d*).*?\\|', output)\n",
    "        if ap_match:\n",
    "            actual_mAP = float(ap_match.group(1))\n",
    "            return actual_mAP\n",
    "            \n",
    "        print(\"Could not parse mAP from output. Full output:\")\n",
    "        print(output[-2000:])  # Last 2000 chars\n",
    "        return None\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"✗ Evaluation timed out (>1 hour)\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error running evaluation: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "# actual_mAP = run_verification(config.SUBSET, 'student')\n",
    "\n",
    "print(\"To run verification, use:\")\n",
    "print(f\"  actual_mAP = run_verification('{config.SUBSET}', 'student')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_all_subsets(subsets_to_verify=None, ckpt_dir=\"pretrained_checkpoints\"):\n",
    "    \"\"\"\n",
    "    Verify results for multiple subsets and compare with claimed values.\n",
    "    \"\"\"\n",
    "    if subsets_to_verify is None:\n",
    "        subsets_to_verify = ['5p', '10p', '20p']  # Default: verify a few subsets\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for subset in subsets_to_verify:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Verifying {subset} subset\")\n",
    "        print('='*50)\n",
    "        \n",
    "        # Download if needed\n",
    "        ckpt_path = os.path.join(WORKSPACE_ROOT, ckpt_dir, subset, f\"coco_{subset}_student.pth\")\n",
    "        if not os.path.exists(ckpt_path):\n",
    "            print(f\"Downloading checkpoints for {subset}...\")\n",
    "            download_checkpoints_for_subset(subset, ckpt_dir)\n",
    "        \n",
    "        # Run evaluation\n",
    "        actual_mAP = run_verification(subset, 'student', ckpt_dir)\n",
    "        expected_mAP = PRETRAINED_CHECKPOINTS[subset]['expected_mAP']\n",
    "        \n",
    "        if actual_mAP is not None:\n",
    "            diff = actual_mAP - expected_mAP\n",
    "            status = \"✓ VERIFIED\" if abs(diff) < 2.0 else \"⚠ DIFFERS\"\n",
    "            results.append({\n",
    "                'subset': subset,\n",
    "                'expected': expected_mAP,\n",
    "                'actual': actual_mAP,\n",
    "                'diff': diff,\n",
    "                'status': status\n",
    "            })\n",
    "            print(f\"\\n{status}: Expected {expected_mAP}%, Got {actual_mAP:.1f}% (diff: {diff:+.1f}%)\")\n",
    "        else:\n",
    "            results.append({\n",
    "                'subset': subset,\n",
    "                'expected': expected_mAP,\n",
    "                'actual': None,\n",
    "                'diff': None,\n",
    "                'status': \"✗ FAILED\"\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def display_verification_results(results):\n",
    "    \"\"\"Display verification results in a nice table\"\"\"\n",
    "    if not results:\n",
    "        print(\"No results to display\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"VERIFICATION RESULTS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Subset':<10} {'Expected':<12} {'Actual':<12} {'Diff':<10} {'Status':<15}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    for r in results:\n",
    "        actual_str = f\"{r['actual']:.1f}%\" if r['actual'] is not None else \"N/A\"\n",
    "        diff_str = f\"{r['diff']:+.1f}%\" if r['diff'] is not None else \"N/A\"\n",
    "        print(f\"{r['subset']:<10} {r['expected']}%{'':<6} {actual_str:<12} {diff_str:<10} {r['status']:<15}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nNote: Paper reports test-dev results; we evaluate on val2017.\")\n",
    "    print(\"      Small differences (<2%) are expected due to this difference.\")\n",
    "\n",
    "# Example: Verify a single subset\n",
    "# results = verify_all_subsets(['5p'])\n",
    "# display_verification_results(results)\n",
    "\n",
    "print(\"To verify results for specific subsets, run:\")\n",
    "print(\"  results = verify_all_subsets(['5p', '10p', '20p'])\")\n",
    "print(\"  display_verification_results(results)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c643f",
   "metadata": {},
   "source": [
    "### Quick Verification Steps\n",
    "\n",
    "**To verify the claimed statistics, follow these steps:**\n",
    "\n",
    "1. **Set your data root** (Cell 3): Update `config.DATA_ROOT` to point to your COCO dataset location\n",
    "\n",
    "2. **Download checkpoints** (run in a cell below):\n",
    "```python\n",
    "downloaded_paths = download_checkpoints_for_subset('5p')  # Or any subset\n",
    "```\n",
    "\n",
    "3. **Run evaluation** (run in a cell below):\n",
    "```python\n",
    "results = verify_all_subsets(['5p'])  # Verify 5% subset\n",
    "display_verification_results(results)\n",
    "```\n",
    "\n",
    "4. **Or run manually in terminal:**\n",
    "Copy the generated command from the cells above and run in your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INTERACTIVE VERIFICATION CELL\n",
    "# =============================================================================\n",
    "# Uncomment the lines below to run verification\n",
    "\n",
    "# Step 1: Choose which subset to verify\n",
    "SUBSET_TO_VERIFY = \"5p\"  # Options: 1p, 2p, 5p, 10p, 20p, 30p, 50p\n",
    "\n",
    "# Step 2: Download the checkpoint (only needed once)\n",
    "# downloaded_paths = download_checkpoints_for_subset(SUBSET_TO_VERIFY)\n",
    "\n",
    "# Step 3: Run verification\n",
    "# results = verify_all_subsets([SUBSET_TO_VERIFY])\n",
    "# display_verification_results(results)\n",
    "\n",
    "print(f\"Ready to verify subset: {SUBSET_TO_VERIFY}\")\n",
    "print(f\"Expected mAP: {PRETRAINED_CHECKPOINTS[SUBSET_TO_VERIFY]['expected_mAP']}%\")\n",
    "print(\"\\nUncomment the lines above to:\")\n",
    "print(\"  1. Download the pre-trained checkpoint\")\n",
    "print(\"  2. Run evaluation on COCO val2017\")\n",
    "print(\"  3. Compare with claimed results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a25aeb",
   "metadata": {},
   "source": [
    "## 10. Training Log Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a240e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_training_log(log_path):\n",
    "    \"\"\"Parse training log to extract metrics\"\"\"\n",
    "    metrics = {\n",
    "        'iterations': [],\n",
    "        'total_loss': [],\n",
    "        'lr': [],\n",
    "        'time': [],\n",
    "        'segm_AP': [],\n",
    "    }\n",
    "    \n",
    "    if not Path(log_path).exists():\n",
    "        print(f\"Log file not found: {log_path}\")\n",
    "        return metrics\n",
    "    \n",
    "    with open(log_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # Parse training iterations\n",
    "            if 'total_loss' in line:\n",
    "                # Extract iteration number\n",
    "                iter_match = re.search(r'iter: (\\d+)', line)\n",
    "                loss_match = re.search(r'total_loss: ([\\d.]+)', line)\n",
    "                lr_match = re.search(r'lr: ([\\d.e-]+)', line)\n",
    "                \n",
    "                if iter_match and loss_match:\n",
    "                    metrics['iterations'].append(int(iter_match.group(1)))\n",
    "                    metrics['total_loss'].append(float(loss_match.group(1)))\n",
    "                    if lr_match:\n",
    "                        metrics['lr'].append(float(lr_match.group(1)))\n",
    "            \n",
    "            # Parse evaluation metrics\n",
    "            if 'segm/AP' in line:\n",
    "                ap_match = re.search(r'segm/AP: ([\\d.]+)', line)\n",
    "                if ap_match:\n",
    "                    metrics['segm_AP'].append(float(ap_match.group(1)))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def plot_training_metrics(metrics, title=\"Training Metrics\"):\n",
    "    \"\"\"Plot training metrics\"\"\"\n",
    "    if not metrics['iterations']:\n",
    "        print(\"No training metrics to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Loss curve\n",
    "    axes[0, 0].plot(metrics['iterations'], metrics['total_loss'], 'b-', alpha=0.7)\n",
    "    axes[0, 0].set_xlabel('Iteration')\n",
    "    axes[0, 0].set_ylabel('Total Loss')\n",
    "    axes[0, 0].set_title('Training Loss')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning rate\n",
    "    if metrics['lr']:\n",
    "        axes[0, 1].plot(metrics['iterations'], metrics['lr'], 'g-')\n",
    "        axes[0, 1].set_xlabel('Iteration')\n",
    "        axes[0, 1].set_ylabel('Learning Rate')\n",
    "        axes[0, 1].set_title('Learning Rate Schedule')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Smoothed loss\n",
    "    if len(metrics['total_loss']) > 10:\n",
    "        window = min(100, len(metrics['total_loss']) // 10)\n",
    "        smoothed = np.convolve(metrics['total_loss'], np.ones(window)/window, mode='valid')\n",
    "        axes[1, 0].plot(metrics['iterations'][window-1:], smoothed, 'r-')\n",
    "        axes[1, 0].set_xlabel('Iteration')\n",
    "        axes[1, 0].set_ylabel('Smoothed Loss')\n",
    "        axes[1, 0].set_title('Smoothed Training Loss')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # AP over time\n",
    "    if metrics['segm_AP']:\n",
    "        axes[1, 1].plot(range(len(metrics['segm_AP'])), metrics['segm_AP'], 'mo-')\n",
    "        axes[1, 1].set_xlabel('Evaluation Index')\n",
    "        axes[1, 1].set_ylabel('Segmentation AP')\n",
    "        axes[1, 1].set_title('Validation AP')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example: Parse and plot training log\n",
    "# log_path = ADELAIDET_ROOT / \"training_dir\" / teacher_exp_name / \"log.txt\"\n",
    "# metrics = parse_training_log(log_path)\n",
    "# plot_training_metrics(metrics, f\"Teacher Network Training ({config.SUBSET})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b89cf4",
   "metadata": {},
   "source": [
    "## 11. Complete Training Pipeline Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a183260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_complete_pipeline_script(config, train_config):\n",
    "    \"\"\"Generate a complete shell script for the entire training pipeline\"\"\"\n",
    "    \n",
    "    script = f\"\"\"#!/bin/bash\n",
    "# PointWSSIS Complete Training Pipeline\n",
    "# Subset: {config.SUBSET}\n",
    "# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "set -e  # Exit on error\n",
    "\n",
    "# Configuration\n",
    "ROOT=\"{config.DATA_ROOT}\"\n",
    "NGPUS={config.NUM_GPUS}\n",
    "SUBSET=\"{config.SUBSET}\"\n",
    "SEED={config.SEED}\n",
    "\n",
    "export DETECTRON2_DATASETS=${{ROOT}}\n",
    "\n",
    "# Step 1: Train Teacher Network\n",
    "echo \"=== Step 1: Training Teacher Network ===\"\n",
    "cd {ADELAIDET_ROOT}\n",
    "\n",
    "EXP_NAME=\"SOLOv2_R101_coco${{SUBSET}}_teacher\"\n",
    "TRAINSETS=\"('coco_2017_train_${{SUBSET}}_s',)\"\n",
    "TESTSETS=\"('coco_2017_val',)\"\n",
    "\n",
    "OMP_NUM_THREADS=1 python -W ignore tools/train_net.py \\\\\n",
    "    --config-file configs/PointWSSIS/R101_teacher.yaml \\\\\n",
    "    --num-gpus ${{NGPUS}} \\\\\n",
    "    SEED ${{SEED}} \\\\\n",
    "    OUTPUT_DIR training_dir/${{EXP_NAME}} \\\\\n",
    "    DATASETS.TRAIN ${{TRAINSETS}} \\\\\n",
    "    DATASETS.TEST ${{TESTSETS}} \\\\\n",
    "    SOLVER.STEPS {train_config['decay_steps']} \\\\\n",
    "    SOLVER.MAX_ITER {train_config['train_iter']} \\\\\n",
    "    SOLVER.BASE_LR {train_config['learning_rate']} \\\\\n",
    "    MODEL.SOLOV2.PROMPT point \\\\\n",
    "    MODEL.SOLOV2.EVAL_PSEUDO_LABEL True \\\\\n",
    "    TEST.EVAL_PERIOD 5000\n",
    "\n",
    "# Step 2: Generate pseudo labels for weak data\n",
    "echo \"=== Step 2: Generating Pseudo Labels ===\"\n",
    "OMP_NUM_THREADS=1 python -W ignore tools/train_net.py \\\\\n",
    "    --config-file configs/PointWSSIS/R101_teacher.yaml \\\\\n",
    "    --num-gpus ${{NGPUS}} \\\\\n",
    "    --eval-only \\\\\n",
    "    MODEL.WEIGHTS training_dir/${{EXP_NAME}}/model_final.pth \\\\\n",
    "    OUTPUT_DIR inference_dir/${{EXP_NAME}} \\\\\n",
    "    MODEL.SOLOV2.FPN_SCALE_RANGES \"((1,100000),(1,100000),(1,100000),(1,100000),(1,100000))\" \\\\\n",
    "    MODEL.SOLOV2.NMS_TYPE mask \\\\\n",
    "    MODEL.SOLOV2.PROMPT point \\\\\n",
    "    DATASETS.TEST \"('coco_2017_train_${{SUBSET}}_w',)\"\n",
    "\n",
    "# Step 3: Generate predictions for strong data (for MRN training)\n",
    "echo \"=== Step 3: Generating Strong Data Predictions ===\"\n",
    "# Get intermediate checkpoints for diverse predictions\n",
    "CKPT_1=$(ls training_dir/${{EXP_NAME}}/model_*.pth | head -n 1)\n",
    "CKPT_2=$(ls training_dir/${{EXP_NAME}}/model_*.pth | tail -n 2 | head -n 1)\n",
    "\n",
    "OMP_NUM_THREADS=1 python -W ignore tools/train_net.py \\\\\n",
    "    --config-file configs/PointWSSIS/R101_teacher.yaml \\\\\n",
    "    --num-gpus ${{NGPUS}} \\\\\n",
    "    --eval-only \\\\\n",
    "    MODEL.WEIGHTS ${{CKPT_1}} \\\\\n",
    "    OUTPUT_DIR inference_dir/${{EXP_NAME}}_strong_1 \\\\\n",
    "    MODEL.SOLOV2.NMS_TYPE mask \\\\\n",
    "    MODEL.SOLOV2.PROMPT point_with_size \\\\\n",
    "    DATASETS.TEST \"('coco_2017_train_${{SUBSET}}_s',)\"\n",
    "\n",
    "OMP_NUM_THREADS=1 python -W ignore tools/train_net.py \\\\\n",
    "    --config-file configs/PointWSSIS/R101_teacher.yaml \\\\\n",
    "    --num-gpus ${{NGPUS}} \\\\\n",
    "    --eval-only \\\\\n",
    "    MODEL.WEIGHTS ${{CKPT_2}} \\\\\n",
    "    OUTPUT_DIR inference_dir/${{EXP_NAME}}_strong_2 \\\\\n",
    "    MODEL.SOLOV2.NMS_TYPE mask \\\\\n",
    "    MODEL.SOLOV2.PROMPT point_with_size \\\\\n",
    "    DATASETS.TEST \"('coco_2017_train_${{SUBSET}}_s',)\"\n",
    "\n",
    "# Step 4: Train MaskRefineNet\n",
    "echo \"=== Step 4: Training MaskRefineNet ===\"\n",
    "cd {MASKREFINE_ROOT}\n",
    "\n",
    "MRN_EXP_NAME=\"MRN_${{SUBSET}}\"\n",
    "\n",
    "torchrun --standalone --nnodes=1 --nproc_per_node=${{NGPUS}} main.py \\\\\n",
    "    --data_root ${{ROOT}} \\\\\n",
    "    --workspace results \\\\\n",
    "    --exp_name ${{MRN_EXP_NAME}} \\\\\n",
    "    --train_iters {train_config['mrn_train_iters']} \\\\\n",
    "    --warm_iters {train_config['mrn_warm_iters']} \\\\\n",
    "    --val_interval 5000 \\\\\n",
    "    --weak_pth ../AdelaiDet/inference_dir/${{EXP_NAME}}_strong_1/inference/instances_predictions.pth \\\\\n",
    "               ../AdelaiDet/inference_dir/${{EXP_NAME}}_strong_2/inference/instances_predictions.pth \\\\\n",
    "    --gt_json instances_train2017_${{SUBSET}}_s.json \\\\\n",
    "    --eval_pth ../AdelaiDet/inference_dir/${{EXP_NAME}}/inference/instances_predictions.pth \\\\\n",
    "    --amp\n",
    "\n",
    "# Step 5: Merge labels\n",
    "echo \"=== Step 5: Merging Strong and Refined Weak Labels ===\"\n",
    "torchrun --standalone --nnodes=1 --nproc_per_node=${{NGPUS}} merge_strong_and_refined_weak_labels.py \\\\\n",
    "    --data_root ${{ROOT}} \\\\\n",
    "    --ckpt results/${{MRN_EXP_NAME}}/ckpt/best_AP.pt \\\\\n",
    "    --dataset coco \\\\\n",
    "    --size 256 \\\\\n",
    "    --weak_pth ../AdelaiDet/inference_dir/${{EXP_NAME}}/inference/instances_predictions.pth \\\\\n",
    "    --weak_json ${{ROOT}}/coco/annotations/instances_train2017_${{SUBSET}}_w.json \\\\\n",
    "    --strong_json ${{ROOT}}/coco/annotations/instances_train2017_${{SUBSET}}_s.json \\\\\n",
    "    --save_path ${{ROOT}}/coco/annotations/instances_train2017_${{SUBSET}}_sw_refined.json\n",
    "\n",
    "# Step 6: Train Student Network\n",
    "echo \"=== Step 6: Training Student Network ===\"\n",
    "cd {ADELAIDET_ROOT}\n",
    "\n",
    "STUDENT_EXP_NAME=\"SOLOv2_R101_coco${{SUBSET}}_sw_refined\"\n",
    "\n",
    "OMP_NUM_THREADS=1 python -W ignore tools/train_net.py \\\\\n",
    "    --config-file configs/SOLOv2/R101_3x.yaml \\\\\n",
    "    --num-gpus ${{NGPUS}} \\\\\n",
    "    SEED ${{SEED}} \\\\\n",
    "    OUTPUT_DIR training_dir/${{STUDENT_EXP_NAME}} \\\\\n",
    "    DATASETS.TRAIN \"('coco_2017_train_${{SUBSET}}_sw_refined',)\" \\\\\n",
    "    DATASETS.TEST \"('coco_2017_val',)\" \\\\\n",
    "    TEST.EVAL_PERIOD 5000\n",
    "\n",
    "echo \"=== Training Complete! ===\"\n",
    "echo \"Student model saved at: training_dir/${{STUDENT_EXP_NAME}}/model_final.pth\"\n",
    "\"\"\"\n",
    "    return script\n",
    "\n",
    "# Generate and display the complete script\n",
    "complete_script = generate_complete_pipeline_script(config, train_config)\n",
    "print(complete_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8cf78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pipeline script\n",
    "script_path = WORKSPACE_ROOT / f\"train_pipeline_{config.SUBSET}.sh\"\n",
    "with open(script_path, 'w') as f:\n",
    "    f.write(complete_script)\n",
    "print(f\"Pipeline script saved to: {script_path}\")\n",
    "print(f\"Run with: bash {script_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5b5aae",
   "metadata": {},
   "source": [
    "## 12. Summary Statistics Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ed958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_dashboard():\n",
    "    \"\"\"Create a summary dashboard of the training pipeline\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"PointWSSIS Training Pipeline Summary\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nConfiguration:\")\n",
    "    print(f\"  - Dataset: {config.DATASET}\")\n",
    "    print(f\"  - Subset: {config.SUBSET} ({config.SUBSET.replace('p', '')}% fully labeled)\")\n",
    "    print(f\"  - Data Root: {config.DATA_ROOT}\")\n",
    "    print(f\"  - Number of GPUs: {config.NUM_GPUS}\")\n",
    "    \n",
    "    print(f\"\\nTraining Hyperparameters ({config.SUBSET}):\")\n",
    "    for key, value in train_config.items():\n",
    "        print(f\"  - {key}: {value}\")\n",
    "    \n",
    "    print(f\"\\nPipeline Steps:\")\n",
    "    print(f\"  1. Train Teacher Network (SOLOv2)\")\n",
    "    print(f\"     - Config: configs/PointWSSIS/R101_teacher.yaml\")\n",
    "    print(f\"     - Iterations: {train_config['train_iter']}\")\n",
    "    print(f\"  2. Generate Pseudo Labels for Weak Data\")\n",
    "    print(f\"  3. Train MaskRefineNet\")\n",
    "    print(f\"     - Iterations: {train_config['mrn_train_iters']}\")\n",
    "    print(f\"  4. Merge Strong and Refined Weak Labels\")\n",
    "    print(f\"  5. Train Student Network\")\n",
    "    \n",
    "    print(f\"\\nExpected Results (from paper):\")\n",
    "    print(f\"  - COCO test-dev mAP: {EXPECTED_RESULTS.get(config.SUBSET, 'N/A')}%\")\n",
    "    \n",
    "    print(f\"\\nOutput Locations:\")\n",
    "    print(f\"  - Teacher model: AdelaiDet/training_dir/{teacher_exp_name}/\")\n",
    "    print(f\"  - MRN model: MaskRefineNet/results/{mrn_exp_name}/\")\n",
    "    print(f\"  - Student model: AdelaiDet/training_dir/{student_exp_name}/\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "create_summary_dashboard()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
